{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9020c27b-0b11-436f-967f-5ed7f0b2d124",
   "metadata": {},
   "source": [
    "# Cafe Sales Data Wrangling Project\n",
    "\n",
    "This project demonstrates data wrangling and preprocessing skills using a publicly available caf√© sales dataset. The focus is cleaning messy raw data, standardizing formats, handling missing values, and preparing the dataset for further analysis.\n",
    "\n",
    "Note: This project does not include analysis or modeling; it is purely focused on data wrangling.\n",
    "\n",
    "## About the Dataset\n",
    "\n",
    "Source: [Kaggle ‚Äì Cafe Sales Dataset](https://www.kaggle.com/datasets/ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training)\n",
    "\n",
    "The Cafe Sales dataset contains 10,000 rows of synthetic data representing sales transactions in a cafe. This dataset is intentionally \"dirty,\" with missing values, inconsistent data, and errors.\n",
    "\n",
    "Let's view the dataset first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "297cfbf6-a9cb-4158-9cfe-ca320b10ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the required packages\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # To hide package warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340895f-c8a9-4a1a-8f78-b801f3e104b0",
   "metadata": {},
   "source": [
    "## Loading and Checking the Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3dd919c5-e51c-4f3d-912a-c7d71cdcdfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID    Item Quantity Price Per Unit Total Spent  Payment Method  \\\n",
       "0    TXN_1961373  Coffee        2            2.0         4.0     Credit Card   \n",
       "1    TXN_4977031    Cake        4            3.0        12.0            Cash   \n",
       "2    TXN_4271903  Cookie        4            1.0       ERROR     Credit Card   \n",
       "3    TXN_7034554   Salad        2            5.0        10.0         UNKNOWN   \n",
       "4    TXN_3160411  Coffee        2            2.0         4.0  Digital Wallet   \n",
       "\n",
       "   Location Transaction Date  \n",
       "0  Takeaway       2023-09-08  \n",
       "1  In-store       2023-05-16  \n",
       "2  In-store       2023-07-19  \n",
       "3   UNKNOWN       2023-04-27  \n",
       "4  In-store       2023-06-11  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw_cafe_sales.csv')\n",
    "\n",
    "# view the portion of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ca21221b-b3f1-410d-b5a0-3b507c212476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      Transaction ID      Item Quantity Price Per Unit Total Spent  \\\n",
       "0       TXN_1961373    Coffee        2            2.0         4.0   \n",
       "1       TXN_4977031      Cake        4            3.0        12.0   \n",
       "2       TXN_4271903    Cookie        4            1.0       ERROR   \n",
       "3       TXN_7034554     Salad        2            5.0        10.0   \n",
       "4       TXN_3160411    Coffee        2            2.0         4.0   \n",
       "...             ...       ...      ...            ...         ...   \n",
       "9995    TXN_7672686    Coffee        2            2.0         4.0   \n",
       "9996    TXN_9659401       NaN        3            NaN         3.0   \n",
       "9997    TXN_5255387    Coffee        4            2.0         8.0   \n",
       "9998    TXN_7695629    Cookie        3            NaN         3.0   \n",
       "9999    TXN_6170729  Sandwich        3            4.0        12.0   \n",
       "\n",
       "      Payment Method  Location Transaction Date  \n",
       "0        Credit Card  Takeaway       2023-09-08  \n",
       "1               Cash  In-store       2023-05-16  \n",
       "2        Credit Card  In-store       2023-07-19  \n",
       "3            UNKNOWN   UNKNOWN       2023-04-27  \n",
       "4     Digital Wallet  In-store       2023-06-11  \n",
       "...              ...       ...              ...  \n",
       "9995             NaN   UNKNOWN       2023-08-30  \n",
       "9996  Digital Wallet       NaN       2023-06-02  \n",
       "9997  Digital Wallet       NaN       2023-03-02  \n",
       "9998  Digital Wallet       NaN       2023-12-02  \n",
       "9999            Cash  In-store       2023-11-07  \n",
       "\n",
       "[10000 rows x 8 columns]>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see metadata of the dataset\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "83f3199f-3c82-46d2-9c20-aff21c2690d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attributes :  8\n",
      "Attributes of Dataset :  ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
      "Empty values for attributes Transaction ID         0\n",
      "Item                 333\n",
      "Quantity             138\n",
      "Price Per Unit       179\n",
      "Total Spent          173\n",
      "Payment Method      2579\n",
      "Location            3265\n",
      "Transaction Date     159\n",
      "dtype: int64\n",
      "Any duplicate record:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print Data attributes\n",
    "print(\"Total number of attributes : \", len(df.columns))\n",
    "print(\"Attributes of Dataset : \", list(df.columns))\n",
    "print(\"Empty values for attributes\", df.isnull().sum())\n",
    "print(\"Any duplicate record: \", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da03466-1b53-4e79-bb68-b8ab2ad47d19",
   "metadata": {},
   "source": [
    "## Exploring each attribute one by one to see what need to be fixed or transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "40ea7e59-3f73-4814-81d1-a30e99ee5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def check_attribute_quality(df, attribute):\n",
    "    \"\"\"\n",
    "    Performs basic data quality checks on a specified DataFrame column.\n",
    "\n",
    "    This function prints:\n",
    "    - Whether the attribute is numeric or not\n",
    "    - Number of null (missing) values\n",
    "    - Number of duplicate values\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    attribute : str\n",
    "        The column name on which data quality checks are performed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Prints data quality information to the console.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç Attribute: {attribute}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Random Sample data from the attribute: \", list(df[attribute].sample(n=100, random_state=42)))\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Is Numeric:\",\n",
    "          pd.api.types.is_numeric_dtype(df[attribute]))\n",
    "    \n",
    "    print(\"Null values:\",\n",
    "          df[attribute].isnull().sum())\n",
    "    \n",
    "    print(\"Duplicate values:\",\n",
    "          df[attribute].duplicated().sum())\n",
    "    \n",
    "    print(\"Are there 'UNKNOWN' values in the Data:\",\n",
    "          'UNKNOWN' in df[attribute].values)\n",
    "    \n",
    "    print(\"Are there 'ERROR' values in the Data:\",\n",
    "          'ERROR' in df[attribute].values)\n",
    "    \n",
    "\n",
    "    \n",
    "def remove_null_values(df, attribute):\n",
    "    \"\"\"\n",
    "    Removes records from a DataFrame where the specified attribute has null values.\n",
    "    Also convert the invalid values to Nan values.\n",
    "    \n",
    "    This function drops rows containing missing (NaN) values in the given column\n",
    "    and reports how many records were removed as part of the cleaning process.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame from which records with null values will be removed.\n",
    "    attribute : str\n",
    "        The column name to check for null values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A cleaned DataFrame with records containing null values in the specified\n",
    "        attribute removed.\n",
    "    \"\"\"\n",
    "    #Replace the invalid values with null values\n",
    "    df[\"Item\"].replace(['ERROR', 'UNKNOWN'], pd.NA, inplace=True)\n",
    "    \n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=[attribute])\n",
    "    after = len(df)\n",
    "    print(\"Total records before removal:\", before)\n",
    "    print(f\"Removed {before - after} rows with missing {attribute} values\")\n",
    "    print(\"Now the total records are:\", after)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def clean_price_per_unit(df, attribute='Price Per Unit'):\n",
    "    \"\"\"\n",
    "    Cleans the Price Per Unit column\n",
    "\n",
    "    Steps:\n",
    "    1. Converts the column to numeric (coercing errors to NaN)\n",
    "    2. Replace the invalid values to NaN and removes rows with null or non-positive values\n",
    "    3. Recalculates Total Spent based on Quantity * Price Per Unit\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing the sales data.\n",
    "    attribute : str, default 'Price Per Unit'\n",
    "        The column name for price values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A cleaned DataFrame with valid Price Per Unit values and consistent Total Spent.\n",
    "    \"\"\"\n",
    "    \n",
    "    before = len(df)\n",
    "    \n",
    "    # 1. Convert to numeric\n",
    "    df[attribute] = pd.to_numeric(df[attribute], errors='coerce')\n",
    "\n",
    "    #Replace the invalid values with null values\n",
    "    df[attribute].replace(['ERROR', 'UNKNOWN'], pd.NA, inplace=True)\n",
    "    \n",
    "    # Drop rows with missing or non-positive prices\n",
    "    df = df[df[attribute] > 0]\n",
    "    \n",
    "    after = len(df)\n",
    "    print(f\"Removed {before - after} rows with invalid or missing {attribute} values\")\n",
    "    print(\"Total records after cleaning:\", after)\n",
    "    \n",
    "    # 3. Recalculate Total Spent\n",
    "    if 'Quantity' in df.columns and 'Total Spent' in df.columns:\n",
    "        df['Total Spent'] = df['Quantity'] * df[attribute]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_column(df, attribute):\n",
    "    \"\"\"\n",
    "    Cleans the Payment Method/location column based on input \n",
    "\n",
    "    Steps:\n",
    "    Replaces invalid entries ('Unknown', 'Error') with NaN and then put \"UNKNOWN\" for all missing values\n",
    "    Standardizes text (capitalization, removes extra spaces)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing sales data.\n",
    "    attribute : str, default 'Payment Method'\n",
    "        The column name to clean.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A cleaned DataFrame with  Payment Method values.\n",
    "    \"\"\"\n",
    "    \n",
    "    before = len(df)    \n",
    "    \n",
    "    # Replace invalid values with NaN\n",
    "    df[attribute] .replace(['ERROR'], pd.NA, inplace=True)\n",
    "\n",
    "    # Replace NaN / NULL with 'UNKNOWN'\n",
    "    df[attribute] = df[attribute].fillna('UNKNOWN')\n",
    "\n",
    "    # Standardize text\n",
    "    df[attribute] = df[attribute].astype(str).str.strip().str.title()    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def clean_transaction_date(df, attribute='Transaction Date', remove_future=True):\n",
    "    \"\"\"\n",
    "    Cleans the Transaction Date column \n",
    "\n",
    "    Steps:\n",
    "    1. Converts the column to datetime, invalid entries become NaT\n",
    "    2. Removes transactions with future dates\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing sales data.\n",
    "    attribute : str, default 'Transaction Date'\n",
    "        The column name to clean.\n",
    "    remove_future : bool, default True\n",
    "        Whether to remove rows with dates in the future.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        A cleaned DataFrame with valid Transaction Date values.\n",
    "    \"\"\"\n",
    "    \n",
    "    before = len(df)\n",
    "    \n",
    "    # 1. Convert to datetime\n",
    "    df[attribute] = pd.to_datetime(df[attribute], errors='coerce')\n",
    "    \n",
    "    # 2. remove future dates\n",
    "    if remove_future:\n",
    "        df = df[df[attribute] <= pd.Timestamp.today()]\n",
    "    \n",
    "    after = len(df)\n",
    "    print(f\"Removed {before - after} rows with invalid or future {attribute} values\")\n",
    "    print(\"Total records after cleaning:\", after)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063bad3e-6611-436e-9eac-8aae9ec9bc85",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Transaction Id\n",
    "<br>Textual data representing the textual transaction Id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "7dbe5d67-000b-490e-96c7-90fa340a9fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Attribute: Transaction ID\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  ['TXN_2919952', 'TXN_4265056', 'TXN_2463115', 'TXN_7619641', 'TXN_9566593', 'TXN_4835929', 'TXN_8320245', 'TXN_3575713', 'TXN_4383002', 'TXN_3656762', 'TXN_1375992', 'TXN_2201857', 'TXN_2710603', 'TXN_4677415', 'TXN_3432433', 'TXN_1721910', 'TXN_3826038', 'TXN_4428252', 'TXN_3202346', 'TXN_5750248', 'TXN_9089045', 'TXN_7051359', 'TXN_5039782', 'TXN_7764175', 'TXN_8798330', 'TXN_4365321', 'TXN_5186460', 'TXN_4431264', 'TXN_6660602', 'TXN_8973007', 'TXN_6795640', 'TXN_9202496', 'TXN_1339158', 'TXN_6755795', 'TXN_8970187', 'TXN_4268167', 'TXN_7313328', 'TXN_7803615', 'TXN_4509329', 'TXN_8811945', 'TXN_6361856', 'TXN_9130559', 'TXN_5530180', 'TXN_4657842', 'TXN_2354774', 'TXN_6688524', 'TXN_7894558', 'TXN_5650608', 'TXN_8092496', 'TXN_3722720', 'TXN_7180164', 'TXN_5315818', 'TXN_2010658', 'TXN_4995281', 'TXN_6751134', 'TXN_1103495', 'TXN_5005592', 'TXN_6219977', 'TXN_1336900', 'TXN_9423451', 'TXN_1022523', 'TXN_4958354', 'TXN_5438422', 'TXN_9547091', 'TXN_1180969', 'TXN_4389662', 'TXN_4624436', 'TXN_3507013', 'TXN_2462604', 'TXN_7905741', 'TXN_6682253', 'TXN_8776606', 'TXN_9822173', 'TXN_8005089', 'TXN_7343905', 'TXN_1982031', 'TXN_3945716', 'TXN_8211303', 'TXN_4623468', 'TXN_8938663', 'TXN_7083611', 'TXN_2964638', 'TXN_8843108', 'TXN_6785552', 'TXN_7738316', 'TXN_6539480', 'TXN_7327440', 'TXN_8676769', 'TXN_4051488', 'TXN_5712248', 'TXN_6559598', 'TXN_8065852', 'TXN_5985513', 'TXN_4907812', 'TXN_9105544', 'TXN_4561006', 'TXN_7519611', 'TXN_1020478', 'TXN_2396191', 'TXN_2110490']\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 0\n",
      "Duplicate values: 0\n",
      "Are there 'UNKNOWN' values in the Data: False\n",
      "Are there 'ERROR' values in the Data: False\n"
     ]
    }
   ],
   "source": [
    "check_attribute_quality(df, 'Transaction ID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75edd450-87ee-44d1-af40-67664f3b7aa0",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:Green;\">_There are no Duplicates or null values for Transaction Id and also by looking at the actual data, this does not need any modification._\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b2c160-7981-4fc7-80c5-2b47ed2d7b32",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Item\n",
    "<br> Name of the item being sold in the transaction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "e70594e3-0c0d-4f4b-a886-9e8a5eeb0733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Attribute: Item\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  ['Juice', 'Juice', 'Sandwich', 'Juice', 'Cake', 'Coffee', 'Tea', nan, 'Coffee', 'Sandwich', 'Coffee', 'Smoothie', 'Smoothie', 'Cake', 'Cookie', 'Juice', 'Salad', 'Sandwich', 'Salad', 'Salad', 'Coffee', 'Coffee', 'Tea', 'Salad', nan, 'Salad', 'Juice', 'Smoothie', nan, 'Coffee', 'Cookie', 'Cake', 'Salad', 'Smoothie', 'Cake', 'Smoothie', 'Juice', 'Salad', 'Tea', 'ERROR', 'Cookie', 'Sandwich', 'Cookie', 'ERROR', 'Coffee', 'Coffee', 'Coffee', 'Juice', 'Juice', 'Salad', 'Sandwich', 'Salad', 'Smoothie', 'Salad', 'Sandwich', 'Juice', 'Coffee', 'Cookie', 'Coffee', 'Coffee', 'Salad', 'Sandwich', 'Smoothie', 'Cookie', 'Cookie', 'Smoothie', 'Sandwich', 'Juice', 'Tea', 'Cookie', 'Tea', 'UNKNOWN', 'Cake', 'Salad', 'Cake', 'Cookie', 'Tea', 'Salad', 'Coffee', 'Coffee', 'Cake', 'Salad', 'Juice', 'Juice', 'Cookie', 'Cake', 'UNKNOWN', 'Salad', 'Cookie', 'Sandwich', 'Juice', 'Sandwich', 'ERROR', 'Sandwich', 'Tea', 'Juice', 'UNKNOWN', 'Coffee', 'Juice', 'ERROR']\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 333\n",
      "Duplicate values: 9989\n",
      "Are there 'UNKNOWN' values in the Data: True\n",
      "Are there 'ERROR' values in the Data: True\n"
     ]
    }
   ],
   "source": [
    "check_attribute_quality(df, 'Item')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aadee6d-16be-4e62-ae94-f9c7589d1ec6",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:Red;\">_There are Duplicates and null values for Items , so let's clean the data for items._\n",
    "</span>\n",
    "<br>Duplicates are fine because transactions are unique, but we need to handle the blank values and there are values where \"UNKNOWN\", \"ERROR\" is written.\n",
    "\n",
    "**Steps**\n",
    "* Replace \"UNKNOWN\" and \"ERROR\" with NaN.\n",
    "* Drop the records for Null Values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "aa334968-14a2-48ff-b51b-a0c87f4eb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records before removal: 10000\n",
      "Removed 969 rows with missing Item values\n",
      "Now the total records are: 9031\n",
      "\n",
      "üîç Attribute: Item\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  ['Sandwich', 'Tea', 'Juice', 'Cake', 'Juice', 'Coffee', 'Cookie', 'Salad', 'Cookie', 'Cake', 'Sandwich', 'Cake', 'Smoothie', 'Smoothie', 'Tea', 'Sandwich', 'Coffee', 'Cake', 'Cake', 'Tea', 'Juice', 'Coffee', 'Tea', 'Tea', 'Cookie', 'Tea', 'Cake', 'Tea', 'Coffee', 'Tea', 'Sandwich', 'Tea', 'Salad', 'Sandwich', 'Juice', 'Cake', 'Salad', 'Salad', 'Cake', 'Cookie', 'Cookie', 'Coffee', 'Sandwich', 'Salad', 'Juice', 'Cookie', 'Cookie', 'Smoothie', 'Coffee', 'Smoothie', 'Tea', 'Sandwich', 'Salad', 'Coffee', 'Cookie', 'Smoothie', 'Smoothie', 'Smoothie', 'Smoothie', 'Cookie', 'Coffee', 'Salad', 'Cake', 'Sandwich', 'Smoothie', 'Coffee', 'Sandwich', 'Coffee', 'Smoothie', 'Cookie', 'Sandwich', 'Tea', 'Sandwich', 'Cake', 'Coffee', 'Smoothie', 'Salad', 'Tea', 'Sandwich', 'Smoothie', 'Smoothie', 'Cake', 'Juice', 'Smoothie', 'Sandwich', 'Cookie', 'Salad', 'Coffee', 'Tea', 'Cake', 'Coffee', 'Tea', 'Cookie', 'Sandwich', 'Smoothie', 'Juice', 'Cookie', 'Cookie', 'Coffee', 'Cake']\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 0\n",
      "Duplicate values: 9023\n",
      "Are there 'UNKNOWN' values in the Data: False\n",
      "Are there 'ERROR' values in the Data: False\n"
     ]
    }
   ],
   "source": [
    "# drop the records for null values\n",
    "df = remove_null_values(df, 'Item')\n",
    "check_attribute_quality(df, 'Item')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82cf5b-45af-4e00-8173-e7268682d6a5",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Quantity\n",
    "<br> Represents how many units of the Item are being sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ad251e72-8413-4982-895a-394a71b9a6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Attribute: Quantity\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  ['4', '1', '1', '3', '1', '1', '4', '3', 'ERROR', '1', '5', '2', '5', '3', '3', '5', '5', 'ERROR', '5', '2', '2', '4', '1', '4', '2', '1', '5', '4', '4', '5', '3', '2', '4', '1', '3', '2', '5', '3', '1', '5', '4', '2', '2', '3', '2', '3', '1', 'ERROR', '2', '4', 'UNKNOWN', '1', '5', '1', '2', '1', '4', '4', '1', '5', '5', '1', '4', '3', '1', '3', '5', 'ERROR', 'UNKNOWN', '3', '5', 'UNKNOWN', '3', '3', '5', '1', '5', '3', '1', '2', '1', '3', '1', '1', '2', '2', '2', '2', '3', '3', '5', '5', '5', '5', '5', '3', '5', '4', '1', '3']\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 121\n",
      "Duplicate values: 9023\n",
      "Are there 'UNKNOWN' values in the Data: True\n",
      "Are there 'ERROR' values in the Data: True\n"
     ]
    }
   ],
   "source": [
    "check_attribute_quality(df, 'Quantity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d6006b-4e1b-49e4-9d5f-a24627aef891",
   "metadata": {},
   "source": [
    "**As the Quantity attribute is not numeric, we need to convert it to numeric to perform analysis later.**\n",
    "\n",
    "Duplicates does not matter for Quantity!\n",
    "\n",
    "We do have null values which is something need to be handled as something must have been sold for the particular transaction!\n",
    "Replace invalid values to NaN.\n",
    "Drop records with null values for quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "9ba43110-e9c6-4475-87ba-ef98a2443924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the quantity into numeric data type and convert any errors into NaN\n",
    "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "894d0128-2e04-476f-a51b-e0ea9561972b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records before removal: 9031\n",
      "Removed 420 rows with missing Quantity values\n",
      "Now the total records are: 8611\n",
      "\n",
      "üîç Attribute: Quantity\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  [1.0, 1.0, 2.0, 4.0, 5.0, 1.0, 2.0, 5.0, 2.0, 1.0, 1.0, 5.0, 5.0, 2.0, 1.0, 5.0, 2.0, 1.0, 1.0, 4.0, 4.0, 5.0, 4.0, 1.0, 3.0, 5.0, 1.0, 4.0, 3.0, 3.0, 3.0, 5.0, 4.0, 3.0, 2.0, 2.0, 2.0, 5.0, 2.0, 5.0, 5.0, 5.0, 1.0, 5.0, 4.0, 1.0, 2.0, 2.0, 4.0, 4.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0, 2.0, 5.0, 2.0, 2.0, 4.0, 4.0, 5.0, 5.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 5.0, 1.0, 5.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 2.0, 4.0, 3.0, 5.0, 2.0, 4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 4.0, 2.0]\n",
      "----------------------------------------\n",
      "Is Numeric: True\n",
      "Null values: 0\n",
      "Duplicate values: 8606\n",
      "Are there 'UNKNOWN' values in the Data: False\n",
      "Are there 'ERROR' values in the Data: False\n"
     ]
    }
   ],
   "source": [
    "# drop the records for null values\n",
    "df = remove_null_values(df, 'Quantity')\n",
    "check_attribute_quality(df, 'Quantity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f5bf0-b488-444d-8e5e-745bb800225a",
   "metadata": {},
   "source": [
    "## 4. Price Per Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "a90ee613-8db5-4223-b43d-32595c64c554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Attribute: Price Per Unit\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  ['4.0', '3.0', '1.0', '4.0', '4.0', '1.0', '3.0', '1.0', '1.5', '3.0', '1.5', '1.5', nan, '4.0', '5.0', '4.0', '3.0', '1.0', '4.0', '3.0', '3.0', '2.0', '3.0', '5.0', '5.0', '2.0', '1.0', '3.0', '4.0', '2.0', '1.0', '2.0', '4.0', '1.5', '4.0', '3.0', '4.0', '1.5', '4.0', '5.0', '4.0', nan, '4.0', '4.0', '3.0', '1.0', '3.0', '4.0', '1.5', '1.5', '3.0', '1.5', '3.0', '4.0', '3.0', '5.0', '4.0', '1.5', 'UNKNOWN', '4.0', '4.0', '3.0', '1.5', '1.5', '2.0', '3.0', '2.0', '5.0', '2.0', '1.0', '1.0', '3.0', '4.0', '5.0', '1.5', '3.0', '5.0', '1.5', '4.0', '3.0', '5.0', '5.0', '3.0', '2.0', '1.0', '3.0', '3.0', '3.0', '3.0', '4.0', '4.0', '3.0', '4.0', '3.0', '4.0', nan, '4.0', '1.0', '1.5', '1.5']\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 153\n",
      "Duplicate values: 8602\n",
      "Are there 'UNKNOWN' values in the Data: True\n",
      "Are there 'ERROR' values in the Data: True\n"
     ]
    }
   ],
   "source": [
    "check_attribute_quality(df, 'Price Per Unit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a6209e-0967-4c05-9656-22fb3f8cbaee",
   "metadata": {},
   "source": [
    "**As the Price Per Unit attribute is not numeric, we need to convert it to numeric to perform analysis later.**\n",
    "\n",
    "Duplicates does not matter for Price Per Unit!\n",
    "\n",
    "We do have null values which is something need to be handled as Item must be worth something for the particular transaction!\n",
    "Replace invalid values to NaN. and drop rows with null values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "c9f64cc5-b482-481e-833e-0ca964c84444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 464 rows with invalid or missing Price Per Unit values\n",
      "Total records after cleaning: 8147\n",
      "\n",
      "üîç Attribute: Price Per Unit\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  [3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 1.0, 1.5, 4.0, 2.0, 3.0, 2.0, 5.0, 3.0, 4.0, 4.0, 1.5, 5.0, 5.0, 1.5, 3.0, 1.5, 2.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 1.5, 4.0, 5.0, 4.0, 3.0, 3.0, 5.0, 3.0, 1.0, 3.0, 1.5, 3.0, 4.0, 3.0, 4.0, 1.0, 3.0, 2.0, 5.0, 1.5, 3.0, 2.0, 3.0, 1.5, 3.0, 1.0, 1.5, 3.0, 3.0, 1.0, 4.0, 5.0, 4.0, 2.0, 3.0, 4.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 1.5, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 2.0, 1.5, 5.0, 5.0, 1.5, 4.0, 4.0, 1.5, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0]\n",
      "----------------------------------------\n",
      "Is Numeric: True\n",
      "Null values: 0\n",
      "Duplicate values: 8141\n",
      "Are there 'UNKNOWN' values in the Data: False\n",
      "Are there 'ERROR' values in the Data: False\n"
     ]
    }
   ],
   "source": [
    "df = clean_price_per_unit(df)\n",
    "check_attribute_quality(df, 'Price Per Unit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed5eda-d8a0-40da-96e0-a8cab0d89fb6",
   "metadata": {},
   "source": [
    "## 5. Total Spent\n",
    "\n",
    "The total amount the user spent in the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "7c1a2440-20ac-4072-95f3-ffb4a711e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Attribute: Total Spent\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  [6.0, 12.0, 12.0, 8.0, 8.0, 15.0, 4.0, 3.0, 20.0, 6.0, 3.0, 10.0, 15.0, 6.0, 12.0, 20.0, 1.5, 20.0, 5.0, 7.5, 12.0, 4.5, 10.0, 10.0, 12.0, 20.0, 6.0, 8.0, 10.0, 7.5, 20.0, 20.0, 12.0, 6.0, 15.0, 25.0, 12.0, 2.0, 9.0, 6.0, 15.0, 12.0, 3.0, 20.0, 3.0, 6.0, 8.0, 10.0, 3.0, 3.0, 10.0, 9.0, 1.5, 6.0, 3.0, 1.5, 12.0, 6.0, 1.0, 8.0, 15.0, 20.0, 8.0, 9.0, 4.0, 4.0, 9.0, 2.0, 9.0, 15.0, 9.0, 16.0, 6.0, 15.0, 15.0, 8.0, 3.0, 3.0, 1.0, 12.0, 4.0, 3.0, 8.0, 2.0, 3.0, 20.0, 25.0, 4.5, 12.0, 20.0, 3.0, 6.0, 2.0, 6.0, 3.0, 8.0, 15.0, 12.0, 12.0, 15.0]\n",
      "----------------------------------------\n",
      "Is Numeric: True\n",
      "Null values: 0\n",
      "Duplicate values: 8130\n",
      "Are there 'UNKNOWN' values in the Data: False\n",
      "Are there 'ERROR' values in the Data: False\n"
     ]
    }
   ],
   "source": [
    "check_attribute_quality(df, 'Total Spent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba99b5de-e2c3-42c2-82b2-3719828d1c6a",
   "metadata": {},
   "source": [
    "**Data looks good for Total Spent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b1d51-e535-4996-8524-6225cb51a0fc",
   "metadata": {},
   "source": [
    "## 6. Payment Method\n",
    "\n",
    "Payment Method user used for the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "775022b5-e051-4a39-abf2-6a7f08f22949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Attribute: Payment Method\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  ['Credit Card', 'Credit Card', 'Digital Wallet', 'Cash', 'Credit Card', 'Credit Card', 'ERROR', nan, 'UNKNOWN', nan, nan, 'Cash', 'Cash', nan, 'Credit Card', 'ERROR', 'UNKNOWN', 'Cash', 'Digital Wallet', nan, 'Credit Card', 'Cash', 'Cash', 'Digital Wallet', 'Cash', nan, 'Digital Wallet', 'Cash', nan, 'Credit Card', nan, 'Credit Card', nan, 'Cash', 'Digital Wallet', 'Credit Card', 'Cash', 'Digital Wallet', 'Credit Card', 'Digital Wallet', nan, 'Cash', 'Cash', 'Digital Wallet', 'Cash', 'ERROR', nan, 'Digital Wallet', nan, 'Digital Wallet', nan, 'Cash', 'Cash', 'Cash', 'Digital Wallet', 'Digital Wallet', 'Digital Wallet', 'Digital Wallet', nan, 'Credit Card', nan, 'UNKNOWN', nan, nan, nan, 'Cash', 'Digital Wallet', 'Digital Wallet', 'Credit Card', 'UNKNOWN', 'Digital Wallet', 'Credit Card', 'Digital Wallet', 'Digital Wallet', 'Credit Card', nan, nan, 'Credit Card', 'Cash', 'Credit Card', 'Credit Card', 'Cash', 'Credit Card', 'Cash', 'Digital Wallet', 'Digital Wallet', 'Credit Card', 'Cash', 'Credit Card', 'Cash', 'Cash', 'Credit Card', 'Digital Wallet', nan, 'Digital Wallet', 'Digital Wallet', 'Digital Wallet', 'Credit Card', 'Digital Wallet', nan]\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 2093\n",
      "Duplicate values: 8141\n",
      "Are there 'UNKNOWN' values in the Data: True\n",
      "Are there 'ERROR' values in the Data: True\n"
     ]
    }
   ],
   "source": [
    "check_attribute_quality(df, 'Payment Method')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fce622-8373-492c-820b-1f98cae41058",
   "metadata": {},
   "source": [
    "**Fixes**\n",
    "* As the data is categorical and needs these categories to follow some standards so that it will make analysis easy and efficient.\n",
    "* Remove extra spaces and Capitilization of the methods.\n",
    "* Remove Invalid Values and records with \"UNKNOWN\" because we want to preserve the data even if payment method is not defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "72889bcc-85e1-4b25-aebe-3e66c1434811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Attribute: Payment Method\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  ['Credit Card', 'Credit Card', 'Digital Wallet', 'Cash', 'Credit Card', 'Credit Card', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Cash', 'Cash', 'Unknown', 'Credit Card', 'Unknown', 'Unknown', 'Cash', 'Digital Wallet', 'Unknown', 'Credit Card', 'Cash', 'Cash', 'Digital Wallet', 'Cash', 'Unknown', 'Digital Wallet', 'Cash', 'Unknown', 'Credit Card', 'Unknown', 'Credit Card', 'Unknown', 'Cash', 'Digital Wallet', 'Credit Card', 'Cash', 'Digital Wallet', 'Credit Card', 'Digital Wallet', 'Unknown', 'Cash', 'Cash', 'Digital Wallet', 'Cash', 'Unknown', 'Unknown', 'Digital Wallet', 'Unknown', 'Digital Wallet', 'Unknown', 'Cash', 'Cash', 'Cash', 'Digital Wallet', 'Digital Wallet', 'Digital Wallet', 'Digital Wallet', 'Unknown', 'Credit Card', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Cash', 'Digital Wallet', 'Digital Wallet', 'Credit Card', 'Unknown', 'Digital Wallet', 'Credit Card', 'Digital Wallet', 'Digital Wallet', 'Credit Card', 'Unknown', 'Unknown', 'Credit Card', 'Cash', 'Credit Card', 'Credit Card', 'Cash', 'Credit Card', 'Cash', 'Digital Wallet', 'Digital Wallet', 'Credit Card', 'Cash', 'Credit Card', 'Cash', 'Cash', 'Credit Card', 'Digital Wallet', 'Unknown', 'Digital Wallet', 'Digital Wallet', 'Digital Wallet', 'Credit Card', 'Digital Wallet', 'Unknown']\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 0\n",
      "Duplicate values: 8143\n",
      "Are there 'UNKNOWN' values in the Data: False\n",
      "Are there 'ERROR' values in the Data: False\n"
     ]
    }
   ],
   "source": [
    "df = clean_column(df, attribute='Payment Method')\n",
    "check_attribute_quality(df, 'Payment Method')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cf3ff1-083b-45df-b9b3-2b0bb106b71c",
   "metadata": {},
   "source": [
    "## 7. Location\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "c6f02a71-dbbc-4512-a325-34cc023e56ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Attribute: Location\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  ['In-store', nan, 'In-store', 'In-store', 'UNKNOWN', nan, 'Takeaway', 'Takeaway', nan, 'In-store', 'UNKNOWN', 'In-store', 'Takeaway', nan, nan, nan, nan, nan, 'In-store', nan, nan, 'Takeaway', nan, nan, 'In-store', 'In-store', nan, 'Takeaway', 'In-store', 'UNKNOWN', 'Takeaway', 'Takeaway', 'Takeaway', 'UNKNOWN', 'In-store', 'In-store', 'In-store', nan, nan, 'Takeaway', nan, 'In-store', 'Takeaway', 'In-store', 'In-store', 'In-store', 'In-store', 'UNKNOWN', 'Takeaway', 'Takeaway', 'In-store', nan, nan, 'In-store', nan, 'Takeaway', nan, nan, nan, 'Takeaway', 'Takeaway', nan, 'Takeaway', 'In-store', 'Takeaway', nan, 'Takeaway', nan, 'UNKNOWN', 'Takeaway', nan, nan, 'Takeaway', 'In-store', nan, 'In-store', 'In-store', 'Takeaway', nan, 'In-store', 'Takeaway', 'In-store', 'In-store', nan, 'In-store', 'In-store', 'UNKNOWN', 'Takeaway', nan, 'In-store', nan, 'Takeaway', nan, nan, 'In-store', 'In-store', nan, nan, 'In-store', nan]\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 2662\n",
      "Duplicate values: 8142\n",
      "Are there 'UNKNOWN' values in the Data: True\n",
      "Are there 'ERROR' values in the Data: True\n"
     ]
    }
   ],
   "source": [
    "check_attribute_quality(df, 'Location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a68376-1b0a-4eb2-92d5-251710fcf624",
   "metadata": {},
   "source": [
    "**Fixes**\n",
    "<br>\n",
    "1. Replaces invalid entries ('ERROR', 'UNKNOWN') and null values with \"UNKNOWN\" just to preserve the data\n",
    "2. Standardizes text (capitalization and removes extra spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "65e3b1e6-7777-4d32-a1e1-b82118ece3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Attribute: Location\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  ['In-Store', 'Unknown', 'In-Store', 'In-Store', 'Unknown', 'Unknown', 'Takeaway', 'Takeaway', 'Unknown', 'In-Store', 'Unknown', 'In-Store', 'Takeaway', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'Unknown', 'In-Store', 'Unknown', 'Unknown', 'Takeaway', 'Unknown', 'Unknown', 'In-Store', 'In-Store', 'Unknown', 'Takeaway', 'In-Store', 'Unknown', 'Takeaway', 'Takeaway', 'Takeaway', 'Unknown', 'In-Store', 'In-Store', 'In-Store', 'Unknown', 'Unknown', 'Takeaway', 'Unknown', 'In-Store', 'Takeaway', 'In-Store', 'In-Store', 'In-Store', 'In-Store', 'Unknown', 'Takeaway', 'Takeaway', 'In-Store', 'Unknown', 'Unknown', 'In-Store', 'Unknown', 'Takeaway', 'Unknown', 'Unknown', 'Unknown', 'Takeaway', 'Takeaway', 'Unknown', 'Takeaway', 'In-Store', 'Takeaway', 'Unknown', 'Takeaway', 'Unknown', 'Unknown', 'Takeaway', 'Unknown', 'Unknown', 'Takeaway', 'In-Store', 'Unknown', 'In-Store', 'In-Store', 'Takeaway', 'Unknown', 'In-Store', 'Takeaway', 'In-Store', 'In-Store', 'Unknown', 'In-Store', 'In-Store', 'Unknown', 'Takeaway', 'Unknown', 'In-Store', 'Unknown', 'Takeaway', 'Unknown', 'Unknown', 'In-Store', 'In-Store', 'Unknown', 'Unknown', 'In-Store', 'Unknown']\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 0\n",
      "Duplicate values: 8144\n",
      "Are there 'UNKNOWN' values in the Data: False\n",
      "Are there 'ERROR' values in the Data: False\n"
     ]
    }
   ],
   "source": [
    "df = clean_column(df, 'Location')\n",
    "check_attribute_quality(df, 'Location')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce9e5f9-7c58-4add-bf40-52648f3759eb",
   "metadata": {},
   "source": [
    "## 8. Transaction Date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "20857abc-812b-41d2-8ef1-af59e407332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Attribute: Transaction Date\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  ['2023-07-20', '2023-03-23', '2023-04-02', '2023-07-08', '2023-04-17', '2023-10-02', '2023-06-18', 'ERROR', '2023-11-18', '2023-12-24', 'UNKNOWN', '2023-04-18', '2023-06-30', '2023-09-03', '2023-02-25', nan, '2023-06-11', '2023-09-02', '2023-09-03', '2023-08-17', '2023-11-30', '2023-03-17', '2023-09-23', '2023-05-22', '2023-04-06', '2023-09-14', '2023-03-28', 'UNKNOWN', 'UNKNOWN', nan, '2023-08-23', '2023-08-26', '2023-07-11', '2023-05-31', nan, '2023-02-20', '2023-06-16', '2023-05-26', '2023-06-12', '2023-02-13', '2023-05-25', '2023-09-10', '2023-10-13', '2023-08-23', '2023-08-29', '2023-08-05', '2023-09-11', '2023-12-23', '2023-04-01', '2023-11-16', '2023-06-20', '2023-12-08', '2023-02-05', '2023-11-26', nan, '2023-05-24', '2023-09-03', '2023-03-10', '2023-04-28', '2023-09-16', '2023-05-01', '2023-08-16', '2023-12-09', '2023-04-23', '2023-06-30', '2023-12-08', '2023-07-16', '2023-11-30', '2023-09-26', '2023-09-06', '2023-04-06', '2023-06-06', '2023-08-11', '2023-01-10', '2023-11-26', '2023-12-19', 'ERROR', '2023-01-14', '2023-07-09', '2023-02-26', '2023-08-20', '2023-03-02', '2023-11-06', '2023-07-15', '2023-08-07', '2023-06-03', '2023-01-04', '2023-03-25', '2023-03-01', '2023-03-30', '2023-06-29', '2023-02-02', '2023-04-16', '2023-06-16', '2023-02-09', '2023-12-30', '2023-12-02', '2023-06-20', '2023-10-25', '2023-12-17']\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 124\n",
      "Duplicate values: 7779\n",
      "Are there 'UNKNOWN' values in the Data: True\n",
      "Are there 'ERROR' values in the Data: True\n"
     ]
    }
   ],
   "source": [
    "check_attribute_quality(df, 'Transaction Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e7075-5a51-4188-967c-02a3ee237f12",
   "metadata": {},
   "source": [
    "**Fixes**\n",
    "1. Converts the column to datetime, invalid entries become NaT\n",
    "2. Removes transactions with future dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "696d1455-7fc8-4ae0-b000-f05e67cca6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 374 rows with invalid or future Transaction Date values\n",
      "Total records after cleaning: 7773\n",
      "\n",
      "üîç Attribute: Transaction Date\n",
      "----------------------------------------\n",
      "Random Sample data from the attribute:  [Timestamp('2023-06-01 00:00:00'), Timestamp('2023-10-03 00:00:00'), Timestamp('2023-04-20 00:00:00'), Timestamp('2023-07-24 00:00:00'), Timestamp('2023-07-14 00:00:00'), Timestamp('2023-09-02 00:00:00'), Timestamp('2023-05-16 00:00:00'), Timestamp('2023-04-14 00:00:00'), Timestamp('2023-05-23 00:00:00'), Timestamp('2023-10-31 00:00:00'), Timestamp('2023-05-01 00:00:00'), Timestamp('2023-08-21 00:00:00'), Timestamp('2023-03-05 00:00:00'), Timestamp('2023-12-20 00:00:00'), Timestamp('2023-11-23 00:00:00'), Timestamp('2023-02-26 00:00:00'), Timestamp('2023-02-13 00:00:00'), Timestamp('2023-04-24 00:00:00'), Timestamp('2023-11-24 00:00:00'), Timestamp('2023-04-14 00:00:00'), Timestamp('2023-02-06 00:00:00'), Timestamp('2023-07-15 00:00:00'), Timestamp('2023-10-20 00:00:00'), Timestamp('2023-11-17 00:00:00'), Timestamp('2023-07-19 00:00:00'), Timestamp('2023-01-27 00:00:00'), Timestamp('2023-10-31 00:00:00'), Timestamp('2023-03-11 00:00:00'), Timestamp('2023-06-14 00:00:00'), Timestamp('2023-03-25 00:00:00'), Timestamp('2023-09-21 00:00:00'), Timestamp('2023-07-01 00:00:00'), Timestamp('2023-01-22 00:00:00'), Timestamp('2023-09-26 00:00:00'), Timestamp('2023-11-13 00:00:00'), Timestamp('2023-12-26 00:00:00'), Timestamp('2023-01-05 00:00:00'), Timestamp('2023-02-27 00:00:00'), Timestamp('2023-03-03 00:00:00'), Timestamp('2023-02-25 00:00:00'), Timestamp('2023-10-09 00:00:00'), Timestamp('2023-01-07 00:00:00'), Timestamp('2023-11-06 00:00:00'), Timestamp('2023-09-05 00:00:00'), Timestamp('2023-10-25 00:00:00'), Timestamp('2023-02-07 00:00:00'), Timestamp('2023-09-06 00:00:00'), Timestamp('2023-05-10 00:00:00'), Timestamp('2023-02-11 00:00:00'), Timestamp('2023-07-10 00:00:00'), Timestamp('2023-06-28 00:00:00'), Timestamp('2023-03-02 00:00:00'), Timestamp('2023-10-06 00:00:00'), Timestamp('2023-08-09 00:00:00'), Timestamp('2023-09-06 00:00:00'), Timestamp('2023-12-19 00:00:00'), Timestamp('2023-09-11 00:00:00'), Timestamp('2023-02-16 00:00:00'), Timestamp('2023-04-02 00:00:00'), Timestamp('2023-03-02 00:00:00'), Timestamp('2023-08-22 00:00:00'), Timestamp('2023-03-25 00:00:00'), Timestamp('2023-02-25 00:00:00'), Timestamp('2023-06-02 00:00:00'), Timestamp('2023-04-18 00:00:00'), Timestamp('2023-12-25 00:00:00'), Timestamp('2023-04-24 00:00:00'), Timestamp('2023-04-17 00:00:00'), Timestamp('2023-08-16 00:00:00'), Timestamp('2023-09-18 00:00:00'), Timestamp('2023-02-10 00:00:00'), Timestamp('2023-06-01 00:00:00'), Timestamp('2023-10-22 00:00:00'), Timestamp('2023-11-09 00:00:00'), Timestamp('2023-11-12 00:00:00'), Timestamp('2023-05-31 00:00:00'), Timestamp('2023-04-29 00:00:00'), Timestamp('2023-07-21 00:00:00'), Timestamp('2023-10-08 00:00:00'), Timestamp('2023-01-04 00:00:00'), Timestamp('2023-12-03 00:00:00'), Timestamp('2023-02-03 00:00:00'), Timestamp('2023-03-26 00:00:00'), Timestamp('2023-10-26 00:00:00'), Timestamp('2023-03-04 00:00:00'), Timestamp('2023-11-13 00:00:00'), Timestamp('2023-08-14 00:00:00'), Timestamp('2023-09-01 00:00:00'), Timestamp('2023-02-24 00:00:00'), Timestamp('2023-09-26 00:00:00'), Timestamp('2023-02-19 00:00:00'), Timestamp('2023-08-10 00:00:00'), Timestamp('2023-04-08 00:00:00'), Timestamp('2023-03-26 00:00:00'), Timestamp('2023-01-29 00:00:00'), Timestamp('2023-04-30 00:00:00'), Timestamp('2023-03-28 00:00:00'), Timestamp('2023-07-27 00:00:00'), Timestamp('2023-09-09 00:00:00'), Timestamp('2023-01-04 00:00:00')]\n",
      "----------------------------------------\n",
      "Is Numeric: False\n",
      "Null values: 0\n",
      "Duplicate values: 7408\n",
      "Are there 'UNKNOWN' values in the Data: False\n",
      "Are there 'ERROR' values in the Data: False\n"
     ]
    }
   ],
   "source": [
    "df = clean_transaction_date(df)\n",
    "check_attribute_quality(df, 'Transaction Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30effd89-9343-42e0-b097-494be1050ca4",
   "metadata": {},
   "source": [
    "# Final Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "cac4cdbf-df3e-4f2e-b2cb-90da43c39c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7773 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Transaction ID    7773 non-null   object        \n",
      " 1   Item              7773 non-null   object        \n",
      " 2   Quantity          7773 non-null   float64       \n",
      " 3   Price Per Unit    7773 non-null   float64       \n",
      " 4   Total Spent       7773 non-null   float64       \n",
      " 5   Payment Method    7773 non-null   object        \n",
      " 6   Location          7773 non-null   object        \n",
      " 7   Transaction Date  7773 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(3), object(4)\n",
      "memory usage: 546.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "648cd782-b065-4076-b8fb-8d7d524cec87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-Store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-Store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-Store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>TXN_2739140</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>In-Store</td>\n",
       "      <td>2023-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>TXN_4766549</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>TXN_7672686</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>TXN_5255387</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2023-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>TXN_6170729</td>\n",
       "      <td>Sandwich</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-Store</td>\n",
       "      <td>2023-11-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7773 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Transaction ID      Item  Quantity  Price Per Unit  Total Spent  \\\n",
       "0       TXN_1961373    Coffee       2.0             2.0          4.0   \n",
       "1       TXN_4977031      Cake       4.0             3.0         12.0   \n",
       "2       TXN_4271903    Cookie       4.0             1.0          4.0   \n",
       "3       TXN_7034554     Salad       2.0             5.0         10.0   \n",
       "4       TXN_3160411    Coffee       2.0             2.0          4.0   \n",
       "...             ...       ...       ...             ...          ...   \n",
       "9992    TXN_2739140  Smoothie       4.0             4.0         16.0   \n",
       "9993    TXN_4766549  Smoothie       2.0             4.0          8.0   \n",
       "9995    TXN_7672686    Coffee       2.0             2.0          4.0   \n",
       "9997    TXN_5255387    Coffee       4.0             2.0          8.0   \n",
       "9999    TXN_6170729  Sandwich       3.0             4.0         12.0   \n",
       "\n",
       "      Payment Method  Location Transaction Date  \n",
       "0        Credit Card  Takeaway       2023-09-08  \n",
       "1               Cash  In-Store       2023-05-16  \n",
       "2        Credit Card  In-Store       2023-07-19  \n",
       "3            Unknown   Unknown       2023-04-27  \n",
       "4     Digital Wallet  In-Store       2023-06-11  \n",
       "...              ...       ...              ...  \n",
       "9992         Unknown  In-Store       2023-07-05  \n",
       "9993            Cash   Unknown       2023-10-20  \n",
       "9995         Unknown   Unknown       2023-08-30  \n",
       "9997  Digital Wallet   Unknown       2023-03-02  \n",
       "9999            Cash  In-Store       2023-11-07  \n",
       "\n",
       "[7773 rows x 8 columns]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "25fce811-cb00-4d42-a54e-2aabaef88ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of attributes :  8\n",
      "Attributes of Dataset :  ['Transaction ID', 'Item', 'Quantity', 'Price Per Unit', 'Total Spent', 'Payment Method', 'Location', 'Transaction Date']\n",
      "Empty values for attributes Transaction ID      0\n",
      "Item                0\n",
      "Quantity            0\n",
      "Price Per Unit      0\n",
      "Total Spent         0\n",
      "Payment Method      0\n",
      "Location            0\n",
      "Transaction Date    0\n",
      "dtype: int64\n",
      "Any duplicate record:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print Data attributes\n",
    "print(\"Total number of attributes : \", len(df.columns))\n",
    "print(\"Attributes of Dataset : \", list(df.columns))\n",
    "print(\"Empty values for attributes\", df.isnull().sum())\n",
    "print(\"Any duplicate record: \", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975bd0ce-d7dd-4733-9d2c-d282505c3c7f",
   "metadata": {},
   "source": [
    "# Export Data to clean CSV - cleaned_cafe_sales.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "9c0f6eb6-80e4-4e33-ab6e-9c904f5e0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "df.to_csv('../data/cleaned_cafe_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7412f4ab-4f4d-4b53-b497-87f743fd93ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584def79-e591-4d69-9a6b-f45139366468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da25d5-0514-497b-b792-5935d76f8e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8317d66b-228c-4d5f-a52d-8255cba81389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c11e42-647a-4383-a147-dda0cbc72759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
